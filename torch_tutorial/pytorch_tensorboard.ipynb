{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91uRYKYzmOcI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOpWNkZgnKAY"
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBeDL2_nnsd2"
   },
   "outputs": [],
   "source": [
    "# Datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "                                             download=False,\n",
    "                                             train=True,\n",
    "                                             transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFSupUNDn0Kh"
   },
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "                                            download=False,\n",
    "                                            train=False,\n",
    "                                            transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNC3d2y6oFPy"
   },
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3_HmdXmohxq"
   },
   "outputs": [],
   "source": [
    "# Constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbEOXg-Yo4if"
   },
   "outputs": [],
   "source": [
    "# Helper function to show an image\n",
    "# (used in the `plot_classes_pred` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "  if one_channel:\n",
    "    img = img.mean(dim=0)\n",
    "  img = img / 2 + 0.5 # Unnormalize\n",
    "  npimg = img.numpy()\n",
    "  if one_channel:\n",
    "    plt.imshow(npimg, cmap='Greys')\n",
    "  else:\n",
    "    plt.imshow(np.transpose(npimage, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1HK46dXp6zI"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "    self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "    self.fc2 = nn.Linear(120, 84)\n",
    "    self.fc3 = nn.Linear(84, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = x.view(-1, 16 * 4 * 4)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nd1JHGNCqzL0"
   },
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fRCYcT2q2VJ"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bj8CExs8vcUl"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\"\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcbsxWgavtS8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset_DataLoaders_transforms.ipynb pytorch_tensorboard.ipynb\r\n",
      "autograd.ipynb                       \u001b[1m\u001b[36mruns\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m                                 what_is_pytorch.ipynb\r\n",
      "neural_net.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0yAuQ5Gv2eT"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write image to out TensorBoard - specifically, a grid - using make_grid\n",
    "# Get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# Show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# Write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Dw2F_nUwdxA"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aL_NDdwiwUdr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26427392it [00:40, 1501651.20it/s]                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\r\n",
      "TensorBoard 2.0.0 at http://localhost:6006/ (Press CTRL+C to quit)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4423680it [00:28, 445168.63it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MEGjVpmbwY7J"
   },
   "outputs": [],
   "source": [
    "# We can visualize the lower dimensional representation of higher dimensional data via\n",
    "# add_embedding method.\n",
    "# Helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "  \"\"\"Select n random datapoints and their corresponding labels from a dataset\"\"\"\n",
    "  assert len(data) == len(labels)\n",
    "\n",
    "  perm = torch.randperm(len(data))\n",
    "  return data[perm][:n], labels[perm][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kH4HQPUozrfH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74x4qq42zYKJ"
   },
   "outputs": [],
   "source": [
    "# Select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# Get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# Log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                     metadata=class_labels,\n",
    "                     label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6s64B740DyO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.0.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the running loss to TensorBoard,\n",
    "# along with a view into the predictions the model\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    \"\"\"Generates predictions and corresponding probabilities from a trained network and a list of images\"\"\"\n",
    "    output = net(images)\n",
    "    # Convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes_preds(net, images, labels):\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # Plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx + 1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title('{0}, {1:.1f}%\\n(label: {2})'.format(classes[preds[idx]], probs[idx] * 100, classes[labels[idx]]),\n",
    "                    color=('green' if preds[idx] == labels[idx].item() else 'red'))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999: # Every 1000 mini-batches\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                             running_loss / 1000,\n",
    "                             epoch * len(trainloader) + i)\n",
    "            \n",
    "            # ...log a Matplotlib Figure showing the model's prediction on a \n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs actual',\n",
    "                             plot_classes_preds(net, inputs, labels),\n",
    "                             global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.0.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing trained models with TensorBoard\n",
    "# 1. Gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. Gets the preds in a test_size Tensor\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "        \n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# Helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    \"\"\"Takes in a 'class_index' from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\"\"\"\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "    \n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                       tensorboard_preds,\n",
    "                       tensorboard_probs,\n",
    "                       global_step=global_step)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\r\n",
      "TensorBoard 2.0.0 at http://localhost:6006/ (Press CTRL+C to quit)\r\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "pytorch_tensorboard.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
