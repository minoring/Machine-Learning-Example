{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Checkpoints.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G80_MEmRcOlH",
        "colab_type": "text"
      },
      "source": [
        "The phrase \"Saving a TensorFlow model\" typically means one of two things:\n",
        "1. Checkpoints, OR\n",
        "2. SavedModel.\n",
        "\n",
        "Checkpoints capture the exact value of all parameters (`tf.Variable` objects) used by a model. Checkpoints do not contain any description of the computation defined by the model and thus are typically only useful when source code that will use the saved parameter values is abailable.\n",
        "\n",
        "The SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint). Models in this format are independent of the source code that created the model. They are thus suitable for deployment via TensorFlow Serving, TensorFlow Lite, Tensorflow.js, or programs in other programming languages (the C, C++, Java, Go, Rust, C# etc. Tensorflow APIs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "214fzXVxbvsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP4eIPjSc8vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(tf.keras.Model):\n",
        "  \"\"\"A simple linear model.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.l1 = tf.keras.layers.Dense(5)\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.l1(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMpS49c0d8_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ7Hh0yCeA9r",
        "colab_type": "text"
      },
      "source": [
        "### Saving from `tf.keras` training APIs\n",
        "See the `tf.keras` guide on saving and restoring.\n",
        "\n",
        "`tf.keras.Model.save_weights` saves a Tensorflow checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT1XkGFQd-B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.save_weights('easy_checkpoint')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P56onE0uemeT",
        "colab_type": "text"
      },
      "source": [
        "### Writing checkpoints\n",
        "The persistent state of a TensorFlow model is stored in `tf.Variable` objects. These can be constructed directly, but are often created through high-level APIs like `tf.keras.layers` or tf.keras.Model.\n",
        "\n",
        "The easiest way to manage variables is by attaching them to Python objects, then referencing those objects.\n",
        "\n",
        "Subclasses of `tf.train.Checkpoint`, tf.keras.layers.Layer`, and `tf.keras.Model` automatically track variables assigned to their attributes. The following example constructs a simple linear model, then writes checkpoints which contain values for all of the model's variables.\n",
        "\n",
        "You can easily save a model-checkpoint with `Model.save_weights`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUmXnuIAfQRo",
        "colab_type": "text"
      },
      "source": [
        "### Manual checkpointing\n",
        "### Setup\n",
        "To help demonstrate all the features of `tf.train.Checkpoint` define a toy dataset and optimization step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5tjc6NmeRvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toy_dataset():\n",
        "  inputs = tf.range(10.)[:, None]\n",
        "  labels = inputs * 5. + tf.range(5.)[None, :]\n",
        "  return tf.data.Dataset.from_tensor_slices(\n",
        "      dict(x=inputs, y=labels)).repeat(10).batch(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq2HXvDmgDQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.range(10.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vOeOBuqfn_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.range(10.)[:, None] # None is newaxis.\n",
        "inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL1UDNCYgCIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " inputs * 5. + tf.range(5.)[None, :]\n",
        " # inputs is shape (10, 1)\n",
        " # tf.range(5.)[None, :] is shape (1, 5)\n",
        "# broadcasting..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVvj089MgUCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(net, example, optimizer):\n",
        "  \"\"\"Trains `net` on `example` using `optimizer`.\"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    output = net(example['x'])\n",
        "    loss = tf.reduce_mean(tf.abs(output - example['y']))\n",
        "  variables = net.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OkAc4y-hJmI",
        "colab_type": "text"
      },
      "source": [
        "### Create the checkpoint objects\n",
        "To manually make a checkpoint you will need a `tf.train.Checkpoint` object. Where the objects you want to checkpoint are set as attributes on the object.\n",
        "\n",
        "A `tf.train.CheckpointManager` can also be helpful for managing multiple checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YHzi8gThHp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(0.1)\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, \n",
        "                           minho=tf.Variable(2))\n",
        "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzECu9DLiEn4",
        "colab_type": "text"
      },
      "source": [
        "### Train and checkpoint the model\n",
        "The following training loop creates an instance of the model and of an optimizer, then gathers them into a `tf.train.Checkpoint` object. It calls the training step in a loop on each batch of data, and periodically writes checkpoints to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za2A9HpViDNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_checkpoint(net, manager):\n",
        "  ckpt.restore(manager.latest_checkpoint)\n",
        "  if manager.latest_checkpoint:\n",
        "    print('Restored from {}'.format(manager.latest_checkpoint))\n",
        "  else:\n",
        "    print('Initializing from scratch.')\n",
        "  \n",
        "  for example in toy_dataset():\n",
        "    loss = train_step(net, example, opt)\n",
        "    ckpt.step.assign_add(1) # 아 이렇게 attribute 접근이 가능하구나...\n",
        "    if int(ckpt.step) % 10 == 0:\n",
        "      save_path = manager.save()\n",
        "      print('Saved checkpoint for step {}: {}'.format(int(ckpt.step), save_path))\n",
        "      print('loss {:1.2f}'.format(loss.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDac6T22jTCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_and_checkpoint(net, manager)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB05U9vOjU72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ckpt.minho"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqq_upFejlh1",
        "colab_type": "text"
      },
      "source": [
        "### Restore and continue training\n",
        "After the first you can pass a new model and manager, but pickup training exactly where you left off:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sg5wkjDjhM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(0.1)\n",
        "net = Net()\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, minho=tf.Variable(3))\n",
        "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
        "\n",
        "train_and_checkpoint(net, manager)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQTyZIVukFUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ckpt.minho # Is 2!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiW9fzlOkOdP",
        "colab_type": "text"
      },
      "source": [
        "The `tf.train.CheckpointManager` object deletes old checkpoints. Above it's configured to keep only the three most recent checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKFyAwxOkJFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(manager.checkpoints)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDZUYcy5kjcL",
        "colab_type": "text"
      },
      "source": [
        "These path, e.g. `tf./tf_ckpts/ckpt-10`, are not files on disk. Instead they are prefixes for an `index` file and one or more data files which contain the variable values. These prefixes are grouped together in a single `checkpoint` file (`./tf_ckpts/checkpoint`) where the `CheckpointManager` saves its state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESym_EcCkb_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls ./tf_ckpts/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFfVq4Ork4or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.latest_checkpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abyvwkYo1pl",
        "colab_type": "text"
      },
      "source": [
        "## Loading mechanics\n",
        "TensorFlow mathes variables to checkpointed values by traversing a directed graph with named edges, starting from the object being loaded. Edge names typically come from attribute names in objects, for example the \"`ll`\" in `self.l` = tf.keras.layers.Dense(5)`. `tf.train.Checkpoint` uses its keyword argument names, as in the \"`step`\" in `tf.train.Checkpoint(step=...).`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVZuKk3bplup",
        "colab_type": "text"
      },
      "source": [
        "Calling `restore()` on a `tf.train.Checkpoint` object queues the requested restorations, restoring variable values as soon as there's a matching path from the `Checkpoint` object. For example we can load just the kernel from the model we defined above by reconstructing one path to it through the network and the layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4y0amIbk8eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_restore = tf.Variable(tf.zeros([5]))\n",
        "print(to_restore.numpy()) # All zeros\n",
        "fake_layer = tf.train.Checkpoint(bias=to_restore)\n",
        "fake_net = tf.train.Checkpoint(l1=fake_layer)\n",
        "new_root = tf.train.Checkpoint(net=fake_net)\n",
        "status = new_root.restore(tf.train.latest_checkpoint('./tf_ckpts/'))\n",
        "print(to_restore.numpy()) # We get restored value now"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}