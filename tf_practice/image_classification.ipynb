{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0kT8T9FTWZi",
        "colab_type": "text"
      },
      "source": [
        "This tutorial shows hot to classify cats or dogs from images.\n",
        "- Building data input pipelines using the `tf.keras.preprocessing.image.ImageDataGenerator` class to efficiently work with data on disk to use with the model.\n",
        "- Overfitting - How to identify and prevent it\n",
        "- Data augmentation and dropout - Key techniques to fight overfitting in computer vision tasks to incorporate into the data pipeline and image classifier model.\n",
        "\n",
        "This tutorial follows a basic machine learning workflow:\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build the model\n",
        "4. Train the model\n",
        "5. Test the model\n",
        "6. Improve the model and repeat the process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrYLrQjMS0mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MCg5DPSVOkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXlu8CyTVonN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "# This tutorial uses a filtered version of Dogs vs Cats dataset from Kaggle/\n",
        "# Download the archive version of the dataset and store it in the \"/tmp\" directory\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyhNSc7FXLdA",
        "colab_type": "text"
      },
      "source": [
        "After extracting its contents, assign variables with the proper file path for the training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv1oL4XGWa_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNtO2I34XakY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats') # directory with out training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCStegcdX7tZ",
        "colab_type": "text"
      },
      "source": [
        "## Understand the data\n",
        "Let's look at how many cats and dogs images are in the training and validation directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf1dlZrnXwbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsVKuXv6Y1Uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhhUhcyBZTln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CedD1XIZVsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_pixels(filepath):\n",
        "    width, height = Image.open(filepath).size\n",
        "    return width, height"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D57ZOBShZhEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width, height = \\\n",
        "        get_num_pixels(os.path.join(train_cats_dir, 'cat.0.jpg'))\n",
        "print('width: ', width);\n",
        "print('height: ', height)\n",
        "\n",
        "width, height = \\\n",
        "        get_num_pixels(os.path.join(train_cats_dir, 'cat.1.jpg'))\n",
        "print('width: ', width);\n",
        "print('height: ', height)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yKasiwfY4gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For convenience, set up variables to use while pre-processing the dataset\n",
        "# and training the network.\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NP568ITaJGu",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation\n",
        "Format the images into appropriately pre-processed floating point tensors before feeding to the network:\n",
        "1. Read images from the disk.\n",
        "2. Decode contents of these images and convert it into proper grid format as per their RGB content.\n",
        "3. Convert them into floating point tensors.\n",
        "4. Resclae the tensors from values between 0 and 255 to values between 0 and 1, as neuralnetworks prefer to deal with small input values\n",
        "\n",
        "We do all these tasks using `ImageDataGenerator` class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puGD9RXjaDbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) #Generator for our training data\n",
        "validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_gH-H92bu_M",
        "colab_type": "text"
      },
      "source": [
        "After defining the generators for training and validation images,\n",
        "the `flow_from_directory` method load images from the disk, applies rescaling, and resizes the images into the required dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ktSNptkbVqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6VWbWXBc-l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvbAhOB2fM-D",
        "colab_type": "text"
      },
      "source": [
        "## Visualize training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lInqgdyEdPLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goMEvkusfWOd",
        "colab_type": "text"
      },
      "source": [
        "The `next` function returns a batch from the dataset. The return value of `next` function is in form of `(x_train, y_train)` where x_train is training features and y_train, its labels. Discard the labels to only visualize the training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KHZENchfTor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_images(imges_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(10, 10))\n",
        "    for img, ax in zip(imges_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltIhpf8CgE06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_image(sample_training_images[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op-R4fozhDeJ",
        "colab_type": "text"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Kw3vB_gIca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    Conv2D(16, (3, 3), padding='same', \n",
        "           activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'), # kerner_size = integer/tuple/list\n",
        "    MaxPooling2D(), # Default pool_size=2\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsKaBmnjjaXG",
        "colab_type": "text"
      },
      "source": [
        "## Compile the model\n",
        "choose the ADAM optimizer and binary crossentropy loss function. To view training and validation accuracy for each training epoch, pass the metrics argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRqqtskgjUzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfqzD4iyjonw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEnrWJ0-j0Vz",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "Use the `fit_generator` method of the `ImageDataGenerator` class to train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYKXFCWTjqQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val//batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFlVGqcblbJA",
        "colab_type": "text"
      },
      "source": [
        "Keras' generators are infinite.\n",
        "\n",
        "Because of this, Keras cannot know by itself how many batches the generators should yield to complete one epoch.\n",
        "\n",
        "validation_steps = Total number of steps (batches of samples) to validate before stopping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkWXftqymksc",
        "colab_type": "text"
      },
      "source": [
        "## Visualize training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFyvp9Melb7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss= history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE8gYZ-Zn3xM",
        "colab_type": "text"
      },
      "source": [
        "Training accuracy and validation accuracy are off by large margin and the model has achieved only around 70% accuracy on the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu4zE8HN84QM",
        "colab_type": "text"
      },
      "source": [
        "## Overfitting\n",
        "In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 70% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable - a sign of overfitting.\n",
        "\n",
        "When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples - to an extent that it negatively impacts the performance of the model on new examples. This phenomenon is known as overfitting. It means that the model will have a difficulty time generalizing on a new dataset.\n",
        "\n",
        "There are multiple ways to fight overfitting in the training process. In this tutorial, you'll use data augmentation and dropout to out model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx2ZHVsN9k_f",
        "colab_type": "text"
      },
      "source": [
        "## Data augmentation\n",
        "Overfitting generally occurs when there are a small number of training examples. One way to fix this problem is to augment the dataset so that it has a suffcient number of training examples. Data augmentation takes the approach of generating more training data from exisiting training samples by augmentiong the samples using random transformations that yield believable-looking images. The goal is the model will never see the exact same picture twice during training. This helps expose the model to more aspects of the data and generalize better.\n",
        "\n",
        "Implement this in `tf.keras` using `ImageDataGenerator` class. Pass different transformation to the dataset and it will take care of applying it during the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OashCOoynfPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply horizontal flip\n",
        "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taMtqShm-qkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed7OVXhl_g7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take one sample image from the training example and repeat it five times\n",
        "# so that the augmentation is applied to the same image five times.\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5UunKEG_-50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_images(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGeYOEiDAByr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ramdonly rotte the image\n",
        "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe-ExkF9AieF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_images(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyH6FoyWAqU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply zoom augmentation to the dataset to zoom images up to 50% randomly.\n",
        "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDgsF0SFBJ5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "augmented_image = [train_data_gen[0][0][0] for _ in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuu1rBNcBYMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_images(augmented_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg6lKX63Bkah",
        "colab_type": "text"
      },
      "source": [
        "## Put it all together\n",
        "APply all the previous augmentations. Here, applied rescale, 45 degree rotation, width shift, height shift, horizontal flip and zoom augmentation to the training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi4oRk3XBbKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=.5\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08ivnVvpCFnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxVqWEzNCRP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize how a single image would look five different times when passing these\n",
        "# augmentations randomly to the dataset.\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plot_images(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSTMYHEtDbGd",
        "colab_type": "text"
      },
      "source": [
        "## Dropout\n",
        "Another technique to reduce overfitting is to introduce *dropout* to the network. It is a form of *regularization* that foces the weights in the network to take only small values, which makes the distribution of weights values more regular and the network can reduce overfitting on small train examples.\n",
        "\n",
        "When appling 0.1 dropout to a certain layer, it randomly kills 10% of the output units in each training epoch. (epoch not batch.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTSeQsNUCexc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a new network with Dropouts\n",
        "model_new = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', \n",
        "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d23aiYHMFb7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_new.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "model_new.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlwS7WnSFpgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model_new.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val//batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30aumwIBF5aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch_range, acc, label='Training Accuracy')\n",
        "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend('lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch_range, loss, label='Training Loss')\n",
        "plt.plot(epoch_range, val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1pBF2G0LBGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}