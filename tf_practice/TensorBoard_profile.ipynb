{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorBoard_profile.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRzTXSuNOZu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzycToYJPB4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import functools\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.python.keras import backend\n",
        "from tensorflow.python.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "print('Tensorflow version: ', tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF-jDXHHPYiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confirm TensorFlow can see the GPU.\n",
        "device_name = tf.config.list_physical_devices(device_type='GPU')\n",
        "if not device_name:\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3XVyowIPqFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_NORM_DECAY = 0.997\n",
        "BATCH_NORM_EPSILON = 1e-5\n",
        "L2_WEIGHT_DECAY = 2e-4\n",
        "\n",
        "\n",
        "def identity_building_block(input_tensor,\n",
        "                            kernel_size,\n",
        "                            filters,\n",
        "                            stage,\n",
        "                            block,\n",
        "                            training=None):\n",
        "  \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "\n",
        "  Args:\n",
        "    input_tensor: input tensor\n",
        "    kernel_size: default 3, the kernel size of\n",
        "        middle conv layer at main path\n",
        "    filters: list of integers, the filters of 3 conv layer at main path\n",
        "    stage: integer, current stage label, used for generating layer names\n",
        "    block: current block label, used for generating layer names\n",
        "    training: Only used if training keras model with Estimator. In other\n",
        "        scenarios it is hadnled automatically.\n",
        "  Returns:\n",
        "    Output tensor for the block.\n",
        "  \"\"\"\n",
        "  filters1, filters2 = filters\n",
        "  if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "    bn_axis = 3\n",
        "  else:\n",
        "    bn_axis = 1\n",
        "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(filters1, kernel_size,\n",
        "                             padding='same',\n",
        "                             kernel_initializer='he_normal',\n",
        "                             kernel_regularizer=\n",
        "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                             bias_regularizer=\n",
        "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                             name=conv_name_base + '2a')(input_tensor)\n",
        "  x = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
        "                                         name=bn_name_base + '2a',\n",
        "                                         momentum=BATCH_NORM_DECAY,\n",
        "                                         epsilon=BATCH_NORM_EPSILON)(\n",
        "                                             x, training=training)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
        "                             padding='same',\n",
        "                             kernel_initializer='he_normal',\n",
        "                             kernel_regularizer=\n",
        "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                             bias_regularizer=\n",
        "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                             name=conv_name_base + '2b')(x)\n",
        "  x = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
        "                                         name=bn_name_base + '2b',\n",
        "                                         momentum=BATCH_NORM_DECAY,\n",
        "                                         epsilon=BATCH_NORM_EPSILON)(\n",
        "                                             x, training=training)                                         \n",
        "  x = tf.keras.layers.add([x, input_tensor])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg9PkxgiXOqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_building_block(input_tensor,\n",
        "                        kernel_size,\n",
        "                        filters,\n",
        "                        stage,\n",
        "                        block,\n",
        "                        strides=(2, 2),\n",
        "                        training=None):\n",
        "  \"\"\"A block that has a conv layer at shortcut.\n",
        "\n",
        "  Arguments:\n",
        "    input_tensor: input_tensor\n",
        "    kernel_size: default 3, the kernel size of\n",
        "        middle conv layer at main path\n",
        "    filters: list of integers, the filters of 3 conv layer at main path\n",
        "    stage: integer, current stage of label, used for generating layer names\n",
        "    block: current block label, used for generating layer names\n",
        "    strides: Strides for first conv layer in the block.\n",
        "    training: Only used if training keras model with Estimator. In other\n",
        "        scenarios it is handled automatically.\n",
        "  Returns:\n",
        "    Output tensor for the block.\n",
        "\n",
        "  Note that from stage 3,\n",
        "  the first conv layer at main path is with strides=(2, 2)\n",
        "  And the shortcut should have strides=(2, 2) as well\n",
        "  \"\"\"\n",
        "  filters1, filters2 = filters\n",
        "  if tf.keras.backend.image_data_format() == 'channel_last':\n",
        "    bn_axis = 3\n",
        "  else:\n",
        "    bn_axis = 1\n",
        "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(filters1, kernel_size, strides=strides,\n",
        "                             padding='same',\n",
        "                             kernel_initializer='he_normal',\n",
        "                             kernel_regularizer=\n",
        "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                             bias_regularizer=\n",
        "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                             name=conv_name_base + '2a')(input_tensor)\n",
        "  x = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
        "                                         name=bn_name_base + '2a',\n",
        "                                         momentum=BATCH_NORM_DECAY,\n",
        "                                         epsilon=BATCH_NORM_EPSILON)(x, training=training)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                             kernel_initializer='he_normal',\n",
        "                             kernel_regularizer=\n",
        "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                             bias_regularizer=\n",
        "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                             name=conv_name_base + '2b')(x)\n",
        "  x = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
        "                                         name=bn_name_base + '2b',\n",
        "                                         momentum=BATCH_NORM_DECAY,\n",
        "                                         epsilon=BATCH_NORM_EPSILON)(\n",
        "                                             x, training=training)\n",
        "\n",
        "  shortcut = tf.keras.layers.Conv2D(filters2, (1, 1), strides=strides,\n",
        "                                    kernel_initializer='he_normal',\n",
        "                                    kernel_regularizer=\n",
        "                                    tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                                    bias_regularizer=\n",
        "                                    tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                                    name=conv_name_base + '1')(input_tensor)\n",
        "  shortcut = tf.keras.layers.BatchNormalization(\n",
        "      axis=bn_axis, name=bn_name_base + '1',\n",
        "      momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(shortcut, training=training)\n",
        "\n",
        "  x = tf.keras.layers.add([x, shortcut])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az7GO704alUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_block(input_tensor,\n",
        "                size,\n",
        "                kernel_size,\n",
        "                filters,\n",
        "                stage,\n",
        "                conv_strides=(2, 2),\n",
        "                training=None):\n",
        "  \"\"\"A block which applies conv followed by multiple identity blocks.\n",
        "\n",
        "  Arguments:\n",
        "    input_tensor: input tensor\n",
        "    size: integer, number of constituent conv/identity building blocks.\n",
        "    A conv block is applied once, followed by (size - 1) identity blocks.\n",
        "    kernel_size: default 3, the kernel size of\n",
        "        middle conv layer at main path\n",
        "    filters: list of integers, the filters of 3 conv layer at main path\n",
        "    stage: integer, current stage label, used for generating layer names\n",
        "    conv_strides: Strides for the first conv layer in the block.\n",
        "    training: Only used if training keras model with Estimator. In other\n",
        "        scenarios it is handled automatically.\n",
        "\n",
        "  Returns:\n",
        "    Output tensor after applying conv and identity blocks.\n",
        "  \"\"\"\n",
        "  x = conv_building_block(input_tensor, kernel_size, filters, stage=stage,\n",
        "                          strides=conv_strides, block='block_0',\n",
        "                          training=training)\n",
        "  for i in range(size - 1):\n",
        "    x = identity_building_block(x, kernel_size, filters, stage=stage,\n",
        "                                block='block_%d' % (i + 1), training=training)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJcsVx1Qe0cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet(num_blocks, classes=10, training=None):\n",
        "  \"\"\"Instantiates the ReNet architecture.\n",
        "\n",
        "  Arguments:\n",
        "    num_blocks: integer, the number of conv/identity blocks in each block.\n",
        "      The Resnet contains 3 blocks with each block containing one conv block\n",
        "      follwed by (layers_per_block - 1) number of identity blocks. Each\n",
        "      conv/identity block has 2 convolutional layers. With the input\n",
        "      convolutional layer and the pooling layer towards the end, this brings\n",
        "      the total size of the network to (6*num_blocks + 2)\n",
        "    classes: optional number of classes to classify image into\n",
        "    training: Only used if training keras model with Estimator. In other\n",
        "    scenarios it is hadnled automatically.\n",
        "\n",
        "  Returns:\n",
        "    A Keras model instance.\n",
        "  \"\"\"\n",
        "  input_shape = (32, 32, 3)\n",
        "  img_input = layers.Input(shape=input_shape)\n",
        "\n",
        "  if backend.image_data_format() == 'channels_first':\n",
        "    x = layers.Lambda(lambda x: backend.permute_dimensions(x, (0, 3, 1, 2)),\n",
        "                      name='transpose')(img_input)\n",
        "    bn_axis = 1\n",
        "  else: # channel_last\n",
        "    x = img_input\n",
        "    bn_axis = 3\n",
        "   \n",
        "  x = tf.keras.layers.ZeroPadding2D(padding=(1, 1), name='conv1_pad')(x)\n",
        "  x = tf.keras.layers.Conv2D(16, (3, 3),\n",
        "                              strides=(1, 1),\n",
        "                              padding='valid',\n",
        "                              kernel_initializer='he_normal',\n",
        "                              kernel_regularizer=\n",
        "                              tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                              bias_regularizer=\n",
        "                              tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                              name='conv1')(x)\n",
        "  x = tf.keras.layers.BatchNormalization(axis=bn_axis, name='bn_conv1',\n",
        "                                         momentum=BATCH_NORM_DECAY,\n",
        "                                         epsilon=BATCH_NORM_EPSILON)(\n",
        "                                             x, training=training)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = resnet_block(x, size=num_blocks, kernel_size=3, filters=[16, 16],\n",
        "                   stage=2, conv_strides=(1, 1), training=training)\n",
        "\n",
        "  x = resnet_block(x, size=num_blocks, kernel_size=3, filters=[32, 32],\n",
        "                   stage=3, conv_strides=(2, 2), training=training)\n",
        "  \n",
        "  x = resnet_block(x, size=num_blocks, kernel_size=3, filters=[64,64],\n",
        "                   stage=4, conv_strides=(2, 2), training=training)\n",
        "  \n",
        "  x = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "  x = tf.keras.layers.Dense(classes, activation='softmax',\n",
        "                            kernel_initializer='he_normal',\n",
        "                            kernel_regularizer=\n",
        "                            tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                            bias_regularizer=\n",
        "                            tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
        "                            name='fc10')(x)\n",
        "\n",
        "  inputs = img_input\n",
        "  # Create model.\n",
        "  model = tf.keras.models.Model(inputs, x, name='resnet56')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq2Kq2HiiU0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet20 = functools.partial(resnet, num_blocks=3)\n",
        "resnet32 = functools.partial(resnet, num_blocks=5)\n",
        "resnet56 = functools.partial(resnet, num_blocks=9)\n",
        "resnet110 = functools.partial(resnet, num_blocks=18)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73fYyoNCijtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download CIFAR-10 data from TensorFlow Datasets.\n",
        "cifar_builder = tfds.builder('cifar10')\n",
        "cifar_builder.download_and_prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hScc-vncjdsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build data input pipeline and compile ResNet56 model.\n",
        "HEIGHT = 32\n",
        "WIDTH = 32\n",
        "NUM_CHANNELS = 3\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "def preprocess_data(record):\n",
        "  image = record['image']\n",
        "  label = record['label']\n",
        "\n",
        "  # Resize the image to add four extra pixels on each side.\n",
        "  image = tf.image.resize_with_crop_or_pad(\n",
        "      image, HEIGHT + 8, WIDTH + 8)\n",
        "  \n",
        "  # Randomly crop a [HEIGHT, WIDTH] section of the image.\n",
        "  image = tf.image.random_crop(image, [HEIGHT, WIDTH, NUM_CHANNELS])\n",
        "\n",
        "  # Randomly flip the image horizontally.\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "  # Subtract off the mean and divide by the variance of the pixels.\n",
        "  image = tf.image.per_image_standardization(image)\n",
        "\n",
        "  label = tf.compat.v1.sparse_to_dense(label, (NUM_CLASSES, ), 1)\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohhzy_0smXvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = cifar_builder.as_dataset(split=tfds.Split.TRAIN)\n",
        "train_data = train_data.repeat()\n",
        "train_data = train_data.map(\n",
        "    lambda value: preprocess_data(value))\n",
        "train_data = train_data.shuffle(1024)\n",
        "train_data = train_data.batch(BATCH_SIZE)\n",
        "\n",
        "# It will prefetch the data in (s-1) step\n",
        "train_data = train_data.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "model = resnet56(classes=NUM_CLASSES)\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK8eL0zbnGPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img, label = next(iter(train_data))\n",
        "print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bMxGR0hpBtA",
        "colab_type": "text"
      },
      "source": [
        "When creating TensorBoard callback, you can specify the batch num you want to profile. By default, TensorFlow will profile second batch, because many one time graph optimizations run one the first batch. You can modify it by setting `profile_batch`. You can also turn off profiling by setting it to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBA4k-ALoAaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This time, you will profile on the third batch.\n",
        "log_dir = 'logs/profile/' + datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOwBtI-Xpmki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_data,\n",
        "          steps_per_epoch=20,\n",
        "          epochs=10,\n",
        "          callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSTpBHTMqQIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compress logdir:\n",
        "!tar -zcvf logs.tar.gz logs/profile/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anucb1EWqdfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}