{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_segmentation.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scq3Ol2O-HxA",
        "colab_type": "text"
      },
      "source": [
        "This tutorial focuses on the task of image segmentation, using a modified `U-net`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEypscFk-QnG",
        "colab_type": "text"
      },
      "source": [
        "## Image Segmentation\n",
        "So far we have seen image classification, where the task of the network is to assign a label or class to an input image. However, suppose we want to know where an object is located in the image, the shape of that object, which pixel belongs to which object, etc. In this case you will want to segment the image, i.e., each pixel of the image is given a label. Thus, the **task of image segmentation is to train a neural network to output a pixel-wise mask of the image.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z8JQy3n_DJh",
        "colab_type": "text"
      },
      "source": [
        "The dataset willbe used is Oxfort-IIIT Dataset. The dataset consists of image, their corresponding labels, and pixel-wise masks. The mask are basically labels for each pixel. Each pixel is given one of three categories:\n",
        "- Class 1: Pixel belonging to the pet.\n",
        "- Class 2: Pixel bordering the pet.\n",
        "- Class 3: None of the above / Surrounding pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5hBwsON987S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/examples.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONZsoPwS-OHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf-nightly-2.0-preview\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKVgF4qI_tqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMLfn1JaAFRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The dataset is already included in TensorFlow datasets.\n",
        "# The segmentaiton masks are included in version 3.0.0.\n",
        "dataset, info = tfds.load('oxford_iiit_pet:3.0.0', with_info=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP96LlqFBC_-",
        "colab_type": "text"
      },
      "source": [
        "The following code performs a simple augmentation of flipping an image. In addition, image is normalized to [0, 1]. Finally, as mentioned above the pixels in the segmentaion mask are labeled either {1, 2, 3}. For the sake of convinience, subtract 1 from the segmentaion mask, resulting in labrels that are: {0, 1, 2}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUZPJv4nAaBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -= 1\n",
        "  return input_image, input_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34oFCosFBwsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def load_image_train(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GuFJ0N1CtvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_test(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "  \n",
        "  return input_image, input_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKk7Z8GnDEcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The dataset already contains the required splits of test and train\n",
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1024\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIAAtQLhDWSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = dataset['train'].map(load_image_train)\n",
        "test = dataset['test'].map(load_image_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvf8hu-FOeaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd3vZ4eqD9Hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w16_Nig8OEgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for img, mask in train_dataset.take(1):\n",
        "  print(img) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1BwTKydThMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i + 1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMFSYRHtXRlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image, mask in train.take(1):\n",
        "  sample_image, sample_mask = image, mask\n",
        "display([sample_image, sample_mask])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBrhAf8IZYeK",
        "colab_type": "text"
      },
      "source": [
        "### Define the model\n",
        "The model being used here is modified U-Net. A U-Net consists of an encoder(downsampler) and decoder(upsampler). In-order to learn robust features, and reduce the number of trainable parameters, a pretrained model can be used as the encoder. Thus, the encoder for this task will be a pretrained MobileNetV2 model, whose intermediate outputs will be used, and the decoder will be the upsample block already implemented.\n",
        "\n",
        "The reason to output three channels is because there are three possible labels for each pixel. Think of this as multi-classification where each pixel is being classified into three classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDsy20vcXcn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ly28YJNaJHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
        "\n",
        "# Use the activations of these layers\n",
        "layer_names = [\n",
        "  'block_1_expand_relu',  # 64x64\n",
        "  'block_3_expand_relu',  # 32x32\n",
        "  'block_6_expand_relu',  # 16x16\n",
        "  'block_13_expand_relu', # 8x8\n",
        "  'block_16_project',     # 4x4\n",
        "]\n",
        "\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "down_stack.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvSa9t68bLuE",
        "colab_type": "text"
      },
      "source": [
        "The decoder/upsampler is simple a seris of upsample blocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxBtkZiYbI63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3), # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3), # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),  # 32x32 -> 64x64\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnpDSimMbnYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unet_model(output_channels):\n",
        "  # This is the last layer of the model\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      output_channels, 3, strides=2,\n",
        "      padding='same', activation='softmax') # 64x64 -> 128x128\n",
        "    \n",
        "  inputs = tf.keras.layers.Input(shape=(128, 128, 3))\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNDYGyDtdCtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = unet_model(OUTPUT_CHANNELS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7f4fsSIdHDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpLz4GLzeZGS",
        "colab_type": "text"
      },
      "source": [
        "### Train the model\n",
        "Now, all that is left to do is to compile and train the model. The loss being used here is losses.sparse_categorical_crossentropy. The reason to use this loss function is because the network is trying to assign each pixel a label, just like multi-class prediction. In the true segmentation mask, each pixel has either a {0,1,2}. The network here is outputting three channels. Essentially, each channel is trying to learn to predict a class, and losses.sparse_categorical_crossentropy is the recommended loss for such a scenario. Using the output of the network, the label assigned to the pixel is the channel with the highest value. This is what the create_mask function is doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uav4r2nMdR9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAtxucpwew7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try out the model to see what is predictios before training.\n",
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3zxgAIAfFeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      pred_mask = model.predict(image)\n",
        "      display([image[0], mask[0], create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([sample_image, sample_mask,\n",
        "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8PJUf9tfZ4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_predictions()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLZ4r_02fayo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo4_BUGmf3cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_STEPS = info.splits['test'].num_examples // BATCH_SIZE // VAL_SUBSPLITS\n",
        "\n",
        "model_history = model.fit(train_dataset,\n",
        "                          epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=test_dataset,\n",
        "                          callbacks=[DisplayCallback()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH7b67oFgPPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "\n",
        "epochs = range(EPOCHS)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "plt.title('Training and Valdidation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzUsNgy1it5K",
        "colab_type": "text"
      },
      "source": [
        "## Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIxLVDYeihiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_predictions(test_dataset, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DyxNGHEizmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}