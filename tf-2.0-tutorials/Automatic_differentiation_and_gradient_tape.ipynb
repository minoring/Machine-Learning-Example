{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic_differentiation_and_gradient_tape.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yP-NQ-xQvCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3d265d0-45ae-4256-cc47-2cea43551d85"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KkrQX33SFKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.ones((2, 2))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = tf.reduce_sum(x)\n",
        "  z = tf.multiply(y, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFVRMqNdS0x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derivative of z with repect to the original input tensor x\n",
        "dz_dx = tape.gradient(z, x)\n",
        "for i in [0, 1]:\n",
        "  for j in [0, 1]:\n",
        "    assert dz_dx[i][j] == 8.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzQI5CMATTJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Can also request gradients of the output with respect to\n",
        "# intermediate values computed during \"recorded\" tf.GradientTape context\n",
        "x = tf.ones((2, 2))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = tf.reduce_sum(x)\n",
        "  z = tf.multiply(y, y)\n",
        "\n",
        "# Use the tape to compute the derivatives of z with respect to the\n",
        "# intermediate value y.\n",
        "dz_dy = tape.gradient(z, y)\n",
        "assert dz_dy == 8.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAtXopP5ULkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# By default, the resources held by a GradientTape are released\n",
        "# as soon as GradientTape.gradient() method is called.\n",
        "# To compute multiple gradients over the same computation,\n",
        "# create a `persistent` gradient tape.\n",
        "# This allows multiple calls to the `gradient()` method as\n",
        "# resources are released when the tape object is garbeage collected\n",
        "x = tf.constant(3, dtype=tf.float32)\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  tape.watch(x)\n",
        "  y = x*x\n",
        "  z = y*y\n",
        "dz_dx = tape.gradient(z, x)\n",
        "dy_dx = tape.gradient(y, x)\n",
        "del tape # Drop the reference to the tape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcLG_o6rVGiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recoding control flow\n",
        "def f(x, y):\n",
        "  output = 1.0\n",
        "  for i in range(y):\n",
        "    if i > 1 and i < 5:\n",
        "      output = tf.multiply(output, x)\n",
        "  return output\n",
        "\n",
        "def grad(x, y):\n",
        "  with tf.GradientTape() as t:\n",
        "    t.watch(x)\n",
        "    out = f(x, y)\n",
        "  return t.gradient(out, x)\n",
        "\n",
        "x = tf.convert_to_tensor(2.0)\n",
        "\n",
        "assert grad(x, 6).numpy() == 12.0\n",
        "assert grad(x, 5).numpy() == 12.0\n",
        "assert grad(x, 4).numpy() == 4.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9v8awmtWE3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gradient computation is recorded as well.\n",
        "x = tf.Variable(1.0)\n",
        "\n",
        "with tf.GradientTape() as t:\n",
        "  with tf.GradientTape() as t2:\n",
        "    y = x * x * x\n",
        "  # Compute the gradient the 't' context manager\n",
        "  # which means the gradient computation is differentiable as well.\n",
        "  dy_dx = t2.gradient(y, x)\n",
        "d2y_dx2 = t.gradient(dy_dx, x)\n",
        "\n",
        "assert dy_dx.numpy() == 3.0\n",
        "assert d2y_dx2.numpy() == 6.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzeOKtZvXRr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}